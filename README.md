# dbt Metrics to DataHub Ingestion Script

This standalone Python script ingests dbt metrics from a `manifest.json` file into DataHub as **GlossaryTerms** with full lineage to underlying models/sources.

## üéØ What This Script Does

1. **Reads** your dbt project's `manifest.json` file
2. **Extracts** all metrics with their metadata (type, calculation, dimensions, filters)
3. **Creates** GlossaryTerms in DataHub organized into a glossary hierarchy
4. **Builds** lineage from each metric to its underlying dbt models/sources
5. **Preserves** all dbt metadata (tags, custom properties, descriptions)

## üöÄ Quick Start for First-Time Users

### Step 1: Find Your dbt manifest.json File

The `manifest.json` file is automatically generated by dbt and contains all your project metadata (models, sources, metrics, etc.).

**Where to find it:**
```bash
cd /path/to/your/dbt/project

# manifest.json is always in the target/ directory
ls target/manifest.json
```

**If it doesn't exist, generate it:**
```bash
# Option 1: Compile your dbt project (faster, no database execution)
dbt compile

# Option 2: Run your dbt project (full execution)
dbt run

# Either command creates target/manifest.json
```

**Verify your metrics are in there:**
```bash
# Quick check: count how many metrics are defined
grep -c '"resource_type": "metric"' target/manifest.json
```

### Step 2: Get Your DataHub Connection Details

You need two pieces of information:

**1. DataHub URL (GMS endpoint):**
- Production: `https://your-company.acryl.io`
- Test environment: `https://test-environment.acryl.io`
- Local dev: `http://localhost:8080`

**2. DataHub Access Token:**
1. Log into DataHub UI
2. Click your profile icon (top right) ‚Üí **Settings**
3. Go to **Access Tokens** tab
4. Click **Generate New Token**
5. Give it a name (e.g., "dbt-metrics-ingestion")
6. Copy the token (starts with `eyJ...`)

‚ö†Ô∏è **Save your token!** You won't be able to see it again after closing the dialog.

### Step 3: Install Python Dependencies

```bash
# Make sure you have Python 3.7+
python --version

# Install the DataHub Python SDK
pip install acryl-datahub
```

### Step 4: Run the Script

```bash
# Basic usage (from this repo directory)
python dbt_metrics_to_datahub.py \
  --manifest /path/to/your/dbt/project/target/manifest.json \
  --datahub-url https://your-datahub-instance.com \
  --token eyJ...your-token-here...
```

**Full example with all options:**
```bash
python dbt_metrics_to_datahub.py \
  --manifest ~/dbt/myproject/target/manifest.json \
  --datahub-url https://mycompany.acryl.io \
  --token eyJhbGciOiJIUzI1NiJ9.ey... \
  --glossary-root "MyCompany_Metrics"
```

### Step 5: Verify Success

**You should see output like:**
```
INFO - Processing manifest from: /path/to/manifest.json
INFO - Found 15 metrics in manifest
INFO - Creating glossary root: MyCompany_Metrics
INFO - Created glossary node: Finance
INFO - Created glossary node: Marketing
INFO - Ingested metric: total_revenue ‚Üí Finance/Revenue
INFO - Ingested metric: customer_count ‚Üí Marketing/Acquisition
...
INFO - ‚úÖ Successfully ingested 15 metrics to DataHub!
```

**Then check DataHub UI:**
1. Open your DataHub instance in a browser
2. Click **Glossary** in the left sidebar
3. Find the `MyCompany_Metrics` root node (or whatever you named it)
4. Expand it to see your metrics organized by category! üéâ

---

## üìñ Command Line Options

| Option | Required | Default | Description |
|--------|----------|---------|-------------|
| `--manifest` | ‚úÖ Yes | - | Path to dbt `manifest.json` file |
| `--datahub-url` | No | `http://localhost:8080` | DataHub GMS server URL |
| `--token` | No | - | DataHub authentication token |
| `--platform` | No | `dbt` | Platform name for lineage |
| `--env` | No | `PROD` | Environment for lineage (PROD/DEV/STAGING) |
| `--glossary-root` | No | `dbt_metrics` | Root glossary node name |

---

## üìã Prerequisites Checklist

Before running the script, make sure you have:

- [ ] **dbt project** with metrics defined (dbt 1.0+ required)
- [ ] **manifest.json** generated (`dbt compile` or `dbt run`)
- [ ] **Python 3.7+** installed
- [ ] **acryl-datahub** package installed (`pip install acryl-datahub`)
- [ ] **DataHub GMS URL** (e.g., `https://your-company.acryl.io`)
- [ ] **DataHub Access Token** (generated from Settings ‚Üí Access Tokens)

---

## üìÅ Glossary Organization

The script organizes metrics into a hierarchical glossary structure:

```
dbt_metrics/                    (Root glossary node)
‚îú‚îÄ‚îÄ Finance/                    (Category from meta.datahub_glossary_category)
‚îÇ   ‚îú‚îÄ‚îÄ revenue_total
‚îÇ   ‚îú‚îÄ‚îÄ revenue_growth_rate
‚îÇ   ‚îî‚îÄ‚îÄ profit_margin
‚îú‚îÄ‚îÄ Marketing/
‚îÇ   ‚îú‚îÄ‚îÄ customer_acquisition_cost
‚îÇ   ‚îî‚îÄ‚îÄ conversion_rate
‚îî‚îÄ‚îÄ Uncategorized/              (Metrics without category)
    ‚îî‚îÄ‚îÄ some_metric
```

### Controlling Category Placement

In your dbt metric definition, use the `datahub_glossary_category` meta tag:

```yaml
# dbt_project/models/metrics/revenue.yml
metrics:
  - name: revenue_total
    label: Total Revenue
    description: Sum of all revenue
    type: simple
    type_params:
      measure: revenue_amount
    meta:
      datahub_glossary_category: Finance  # ‚Üê This controls placement!
```

If no category is specified, metrics go into the "Uncategorized" category.

## üîó Lineage Creation

The script automatically creates lineage from each metric to its underlying datasets:

```
Metric (GlossaryTerm)
  ‚îî‚îÄ‚Üí dbt Model (Dataset)
       ‚îî‚îÄ‚Üí Source Table (Dataset)
```

Example:
```
revenue_total (Metric)
  ‚îî‚îÄ‚Üí analytics.finance.revenue_by_date (dbt model)
       ‚îî‚îÄ‚Üí raw.transactions.orders (source)
```

This lineage enables:
- **Impact Analysis**: "Which metrics are affected if I change this model?"
- **Dependency Discovery**: "What data sources does this metric rely on?"
- **Complete Visibility**: Full understanding of metric data dependencies

## üìä What Gets Ingested

For each dbt metric, the script captures:

| DataHub Field | dbt Source | Example |
|---------------|------------|---------|
| **Name** | `metric.label` or `metric.name` | "Total Revenue" |
| **Definition** | `metric.description` | "Sum of all revenue across all channels" |
| **Metric Type** | `metric.type` | "simple", "ratio", "derived", "cumulative" |
| **Calculation** | `metric.calculation_method` | "sum", "average", "count_distinct" |
| **Expression** | `metric.expression` | SQL expression or formula |
| **Dimensions** | `metric.dimensions` | ["date", "region", "product_category"] |
| **Time Grains** | `metric.time_grains` | ["day", "week", "month", "quarter"] |
| **Filters** | `metric.filters` | List of filter conditions |
| **Tags** | `metric.tags` | ["finance", "kpi", "executive"] |
| **Custom Meta** | `metric.meta.*` | Any custom properties you define |

## üß™ Testing Before Production

### 1. Dry Run (Check Your Manifest)

```bash
# Just parse the manifest without emitting to DataHub
python -c "
import json
with open('target/manifest.json') as f:
    manifest = json.load(f)
    metrics = manifest.get('metrics', {})
    print(f'Found {len(metrics)} metrics:')
    for m_id, m in metrics.items():
        print(f'  - {m[\"name\"]}: {m.get(\"description\", \"No description\")[:50]}...')
"
```

### 2. Test with Local DataHub

```bash
# Run against local DataHub quickstart
python dbt_metrics_to_datahub.py \
  --manifest target/manifest.json \
  --datahub-url http://localhost:8080
```

### 3. Verify in DataHub UI

1. Navigate to **Glossary** in DataHub UI
2. Look for the `dbt_metrics` root node
3. Expand categories and check metrics appear with:
   - Correct names and descriptions
   - Custom properties (metric type, calculation, dimensions)
   - Lineage to underlying datasets

## üîß Advanced Usage

### Custom Glossary Structure

```bash
# Use a different root glossary name
python dbt_metrics_to_datahub.py \
  --manifest target/manifest.json \
  --glossary-root "MyCompany_BusinessMetrics"
```

### Multiple Environments

```bash
# Ingest dev metrics separately from prod
python dbt_metrics_to_datahub.py \
  --manifest target/manifest.json \
  --env DEV \
  --glossary-root "dbt_metrics_dev"
```

### Platform-Specific Lineage

```bash
# If your dbt project targets Snowflake
python dbt_metrics_to_datahub.py \
  --manifest target/manifest.json \
  --platform snowflake

# If using BigQuery
python dbt_metrics_to_datahub.py \
  --manifest target/manifest.json \
  --platform bigquery
```

## üêõ Troubleshooting

### Issue: "No metrics found in manifest"

**Cause:** Your dbt version might not have metrics, or they're not compiled.

**Solution:**
1. Check dbt version: `dbt --version` (need dbt 1.0+)
2. Ensure metrics are defined in your project
3. Run `dbt compile` or `dbt run` to generate fresh manifest.json

### Issue: "Could not resolve node X to dataset URN"

**Cause:** The metric references a node that doesn't exist in the manifest.

**Solution:**
- Ensure your manifest.json is up-to-date (`dbt compile`)
- Check that the metric's `depends_on` references valid models/sources

### Issue: "Authentication failed"

**Cause:** Invalid or missing DataHub token.

**Solution:**
1. Generate a token in DataHub UI: Settings ‚Üí Access Tokens ‚Üí Generate Token
2. Pass it via `--token` flag
3. Or set environment variable: `export DATAHUB_TOKEN=your-token`

### Issue: "Connection refused to DataHub"

**Cause:** DataHub GMS is not accessible at the specified URL.

**Solution:**
- Verify DataHub is running: `curl http://your-datahub:8080/health`
- Check firewall/network settings
- Ensure you're using the GMS URL (port 8080), not the frontend (port 9002)

## üìà Next Steps After Testing

Once you've validated the script works for your use case:

1. **Automate**: Add this script to your dbt CI/CD pipeline
   ```bash
   # In your dbt CI pipeline
   dbt run
   dbt compile
   python dbt_metrics_to_datahub.py --manifest target/manifest.json
   ```

2. **Schedule**: Run periodically to keep metrics in sync
   ```bash
   # Cron job or Airflow DAG
   0 */6 * * * cd /dbt/project && python dbt_metrics_to_datahub.py ...
   ```

3. **Extend**: Add support for semantic models (dbt 1.6+)
   - The script has a `parse_semantic_models()` stub ready to go
   - Emit semantic models as Datasets with lineage to metrics

4. **Productionize**: Work with DataHub team to integrate this into the native dbt connector
   - This becomes a standard feature
   - All customers benefit
   - No script maintenance required

## ü§ù Support

Questions or issues?
- Open an issue in this GitHub repository
- Reach out to the Acryl Data/DataHub team

---

**License:** Apache 2.0
**Maintainer:** Acryl Data
